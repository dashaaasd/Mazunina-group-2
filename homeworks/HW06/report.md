# HW06 – Report

> Файл: `homeworks/HW06/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Dataset

- Какой датасет выбран: `S06-hw-dataset-02.csv`
- Размер: (строк, столбцов) (18000, 39)
- Целевая переменная: `target` (классы и их доли) Класс 0: 73.74%, Класс 1: 26.26%
- Признаки: что за типы (числовые / категориальные-подобные, если есть) 37 числовых(float64) признаков

## 2. Protocol

- Разбиение: train/test (доли, `random_state`) train: (14400, 37)(80 %), , test:  (3600, 37) (20%), random_state=42
- Подбор: CV на train (сколько фолдов, что оптимизировали) 5-fold CV, оптимизация ROC-AUC
- Метрики: accuracy, F1, ROC-AUC (и почему эти метрики уместны именно здесь) Accuracy, Precision, Recall, F1-score, ROC-AUC,
Почему эти метрики уместны:
  1. **Accuracy** - общая точность модели, хороший базовый показатель
  2. **Precision и Recall** - критичны для задач с дисбалансом классов (в моем датасете явный дисбаланс классов):
     - **Precision** - важно минимизировать ложные срабатывания
     - **Recall** - важно минимизировать пропуски
  3. **F1-score** - гармоническое среднее Precision и Recall, показывает баланс между ними
  4. **ROC-AUC** - основная метрика для сравнения моделей, показывает способность модели различать классы на всех порогах, устойчива к дисбалансу

## 3. Models

Опишите, какие модели сравнивали и какие гиперпараметры подбирали.

Минимум:

- DummyClassifier (baseline) Стратегия: most_frequent
Стратегия: `most_frequent` (предсказывает самый частый класс)
Назначение: Базовый уровень для сравнения, показывает минимально достижимую производительность без обучения
Параметры: Без подбора гиперпараметров

- LogisticRegression (baseline из S05)
Назначение: Линейная базовая модель для сравнения со сложными алгоритмами
Параметры: Без подбора гиперпараметров
Препроцессинг: StandardScaler в пайплайне

- DecisionTreeClassifier (контроль сложности: `max_depth` + `min_samples_leaf` или `ccp_alpha`)
Назначение: Простое дерево решений для понимания вклада признаков
Подбираемые гиперпараметры (контроль сложности):
  - `max_depth`: [3, 5, 7, 10, 15, None] — максимальная глубина
  - `min_samples_leaf`: [1, 2, 5, 10, 20] — минимальное количество образцов в листе
  - `min_samples_split`: [2, 5, 10] — минимальное количество для разделения
  - `ccp_alpha`: [0.0, 0.001, 0.01, 0.1] — параметр cost-complexity pruning
- Всего комбинаций: 6 × 5 × 3 × 4 = 360 вариантов
Лучшие параметры DecisionTree:
- `max_depth`: 10
- `min_samples_leaf`: 20  
- `ccp_alpha`: 0.0
- `min_samples_split`: 2

- RandomForestClassifier
Назначение: Ансамбль деревьев, устойчивый к переобучению
Подбираемые гиперпараметры:
  - `n_estimators`: [100] — количество деревьев
  - `max_depth`: [10, 20, None] — максимальная глубина
  - `min_samples_leaf`: [1, 4] — минимальное количество в листе
  - `max_features`: ['sqrt', '0.3'] — количество признаков для разделения
  - `bootstrap`: [True] — бутстрап выборки
- Всего комбинаций: 1 × 3 × 2 × 2 × 1 = 12 вариантов
Лучшие параметры RandomForestClassifier:
- `n_estimators`: 100
- `max_depth`: 20
- `min_samples_leaf`: 1
- `max_features`: 'sqrt'
- `bootstrap`: True

- Один boosting (AdaBoost / GradientBoosting / HistGradientBoosting)
GradientBoostingClassifier
Назначение: Бустинговый ансамбль, последовательное улучшение предсказаний
Подбираемые гиперпараметры:
  - `n_estimators`: [100] — количество деревьев
  - `learning_rate`: [0.05, 0.1] — скорость обучения
  - `max_depth`: [3, 5] — глубина деревьев
  - `subsample`: [0.8] — доля выборки для обучения каждого дерева
  - `min_samples_split`: [2, 5] — минимальное количество для разделения
  - `min_samples_leaf`: [1] — минимальное количество в листе
- Всего комбинаций: 1 × 2 × 2 × 1 × 2 × 1 = 8 вариантов
**GradientBoosting**:
- `n_estimators`: 100
- `learning_rate`: 0.1
- `max_depth`: 5
- `subsample`: 0.8
- `min_samples_split`: 5
- `min_samples_leaf`: 1

Опционально:

- StackingClassifier (с CV-логикой)
Назначение: Мета-ансамбль, комбинирующий предсказания базовых моделей
Базовая архитектура:
  - Базовые модели (Level-0):
    1. `DecisionTreeClassifier` (best_dt)
    2. `RandomForestClassifier` (best_rf)
    3. `GradientBoostingClassifier` (best_gb)
  - Мета-модель (Level-1): `LogisticRegression`
- Конфигурация:
  - `cv`: 5 — стратифицированная 5-фолдовая кросс-валидация
  - `passthrough`: False — использование только мета-признаков
  - `stack_method`: 'auto' — автоматический выбор метода стекинга
- Параметры мета-модели:
  - `C`: 1.0
  - `max_iter`: 1000
  - `random_state`: 42

## 4. Results

- Таблица/список финальных метрик на test по всем моделям

| Модель | Accuracy | Precision | Recall | F1-score | ROC-AUC |
|--------|----------|-----------|--------|----------|---------|
| Stacking | 0.9039 | 0.8622 | 0.7545 | 0.8047 | 0.9273 |
| RandomForest | 0.8903 | 0.9129 | 0.6434 | 0.7548 | 0.9261 |
| GradientBoosting | 0.8972 | 0.8778 | 0.7069 | 0.7831 | 0.9221 |
| DecisionTree | 0.8336 | 0.7235 | 0.5926 | 0.6515 | 0.8374 |
| LogisticRegression | 0.8119 | 0.7248 | 0.4571 | 0.5607 | 0.7977 |
| Dummy Baseline | 0.7375 | 0.0000 | 0.0000 | 0.0000 | 0.5000 |

- Победитель (по ROC-AUC или по согласованному критерию) и краткое объяснением
 **Stacking Classifier**
Краткое объяснение:
  Stacking Classifier показал наивысший **ROC-AUC = 0.9273**, превзойдя все отдельные модели. Это объясняется способностью мета-ансамбля: Комбинирование сильных сторон: Stacking объединил предсказания трех лучших базовых моделей (DecisionTree, RandomForest, GradientBoosting), используя LogisticRegression как мета-модель для "обучения" оптимального взвешивания их предсказаний

## 5. Analysis

- Устойчивость: что будет, если поменять `random_state` (хотя бы 5 прогонов для 1-2 моделей) – кратко

Для проверки устойчивости проведено 5 прогонов с разными значениями `random_state` для двух моделей: **RandomForest** и **GradientBoosting**. Цель — оценить, насколько результаты зависят от случайного разбиения данных.

**Результаты экспериментов**:

| random_state | RandomForest (AUC) | GradientBoosting (AUC) |
|------|--------------------|------------------------|
| 42 | 0.9262 | 0.8962 |
| 123 | 0.9285 | 0.8967 |
| 777 | 0.9347 | 0.9085 |
| 999 | 0.9338 | 0.9066 |
| 2024 | 0.9262 | 0.9013 |

Статистический анализ:

- **RandomForest**: Средний AUC = 0.9299 ± 0.0037 (диапазон: 0.9262-0.9347)
- **GradientBoosting**: Средний AUC = 0.9019 ± 0.0050 (диапазон: 0.8962-0.9085)

В основном эксперименте GradientBoosting показал лучший результат, однако при проверке устойчивости RandomForest демонстрирует:

- Более высокое среднее значение (0.9299 vs 0.9019)
- Лучшую устойчивость (меньший разброс)

- Ошибки: confusion matrix для лучшей модели + комментарий

| | Predicted 0 | Predicted 1 |
|---|---|---|
| **Actual 0** | 2547 | 108 |
| **Actual 1** | 233 | 712 |

- Общая точность: 90.39%
- Пропущенные положительные (FN): 233 (24.6% от всех положительных)
- Ложные срабатывания (FP): 108 (4.1% от всех отрицательных)
- Модель демонстрирует консервативную стратегию: минимизирует ложные срабатывания, но пропускает часть положительных случаев.

- Интерпретация: permutation importance (top-10/15) + выводы

**Топ-10 самых важных признаков**:

| Ранг | Признак | Важность (ΔROC-AUC) |
|------|---------|-------------------|
| 1 | `f16` | 0.0627 ± 0.0043 |
| 2 | `f01` | 0.0207 ± 0.0018 |
| 3 | `f07` | 0.0146 ± 0.0016 |
| 4 | `f19` | 0.0129 ± 0.0016 |
| 5 | `f12` | 0.0112 ± 0.0007 |
| 6 | `f08` | 0.0109 ± 0.0009 |
| 7 | `f30` | 0.0099 ± 0.0008 |
| 8 | `f23` | 0.0098 ± 0.0017 |
| 9 | `f18` | 0.0093 ± 0.0009 |
| 10 | `f15` | 0.0082 ± 0.0010 |

1. Признак `f16` доминирует с важностью 0.0627, что в 3 раза больше, чем у второго по важности признака `f01`. Перестановка `f16` снижает ROC-AUC  — это критически важный признак для модели.

2. Топ-5 признаков (`f16`, `f01`, `f07`, `f19`, `f112`) обеспечивают **~65%** общей объяснительной силы

## 6. Conclusion

3-6 коротких тезисов: что вы поняли про деревья/ансамбли и про честный ML-протокол.

О деревья/ансамблях:
Важно правильно регулировать деревья, чтобы они не переобучались, тогда они становятся устойчивой моделью.
Ансамбли значительно превосходят одиночные модели, но нужно правильно выбирать бэггинг или бустинг в зависимости от того, что требуется (интерпретируемость, устоичивость).
Объединение моделей через Stacking дает наилучший результат, что подверждает, что несколько объединеных моделей умнее одной.
О честном ML-протоколе:
1. Фиксированный random_state=42 обеспечил воспроизводимость всех экспериментов.
2. Стратифицированное разбиение сохранило распределение классов (26.3%/73.7%) в train/test выборках.
3. Строгое разделение на train/test (80/20) и использование только CV на train для подбора параметров предотвратило "утечку" информации из test-выборки.
4. Множество метрик (Accuracy, Precision, Recall, F1, ROC-AUC) позволило всесторонне оценить модели, особенно важны Precision и Recall при дисбалансе классов.