# HW06 – Report

> Файл: `homeworks/HW06/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Dataset

- Какой датасет выбран: `S06-hw-dataset-02.csv`
- Размер: (строк, столбцов) (18000, 39)
- Целевая переменная: `target` (классы и их доли) Класс 0: 73.74%, Класс 1: 26.26%
- Признаки: что за типы (числовые / категориальные-подобные, если есть) 37 числовых(float64) признаков

## 2. Protocol

- Разбиение: train/test (доли, `random_state`) train: (10800, 37)(60 %), val:   (3600, 37) (20%), test:  (3600, 37) (20%), random_state=42
- Подбор: CV на train (сколько фолдов, что оптимизировали) 5-fold CV, оптимизация ROC-AUC
- Метрики: accuracy, F1, ROC-AUC (и почему эти метрики уместны именно здесь) Accuracy, Precision, Recall, F1-score, ROC-AUC,
Почему эти метрики уместны:
  1. **Accuracy** - общая точность модели, хороший базовый показатель
  2. **Precision и Recall** - критичны для задач с дисбалансом классов (в моем датасете явный дисбаланс классов):
     - **Precision** - важно минимизировать ложные срабатывания
     - **Recall** - важно минимизировать пропуски
  3. **F1-score** - гармоническое среднее Precision и Recall, показывает баланс между ними
  4. **ROC-AUC** - основная метрика для сравнения моделей, показывает способность модели различать классы на всех порогах, устойчива к дисбалансу

## 3. Models

Опишите, какие модели сравнивали и какие гиперпараметры подбирали.

Минимум:

- DummyClassifier (baseline) Стратегия: most_frequent
Стратегия: `most_frequent` (предсказывает самый частый класс)
Назначение: Базовый уровень для сравнения, показывает минимально достижимую производительность без обучения
Параметры: Без подбора гиперпараметров
- LogisticRegression (baseline из S05)
Назначение: Линейная базовая модель для сравнения со сложными алгоритмами
Параметры: Без подбора гиперпараметров
Препроцессинг: StandardScaler в пайплайне
- DecisionTreeClassifier (контроль сложности: `max_depth` + `min_samples_leaf` или `ccp_alpha`)
Назначение: Простое дерево решений для понимания вклада признаков
Подбираемые гиперпараметры (контроль сложности):
  - `max_depth`: [3, 5, 7, 10, 15, None] — максимальная глубина
  - `min_samples_leaf`: [1, 2, 5, 10, 20] — минимальное количество образцов в листе
  - `min_samples_split`: [2, 5, 10] — минимальное количество для разделения
  - `ccp_alpha`: [0.0, 0.001, 0.01, 0.1] — параметр cost-complexity pruning
- Всего комбинаций: 6 × 5 × 3 × 4 = 360 вариантов
Лучшие параметры DecisionTree:
- `max_depth`: 10
- `min_samples_leaf`: 20  
- `ccp_alpha`: 0.0
- `min_samples_split`: 2
Лучший ROC-AUC на CV: 0.8201
- RandomForestClassifier
Назначение: Ансамбль деревьев, устойчивый к переобучению
Подбираемые гиперпараметры:
  - `n_estimators`: [100] — количество деревьев
  - `max_depth`: [10, 20, None] — максимальная глубина
  - `min_samples_leaf`: [1, 4] — минимальное количество в листе
  - `max_features`: ['sqrt', '0.3'] — количество признаков для разделения
  - `bootstrap`: [True] — бутстрап выборки
- Всего комбинаций: 1 × 3 × 2 × 2 × 1 = 12 вариантов
Лучшие параметры RandomForestClassifier:
- `n_estimators`: 100
- `max_depth`: 20
- `min_samples_leaf`: 1
- `max_features`: 'sqrt'
- `bootstrap`: True
Лучший ROC-AUC на CV: 0.9222
- Один boosting (AdaBoost / GradientBoosting / HistGradientBoosting)
GradientBoostingClassifier
Назначение: Бустинговый ансамбль, последовательное улучшение предсказаний
Подбираемые гиперпараметры:
  - `n_estimators`: [100] — количество деревьев
  - `learning_rate`: [0.05, 0.1] — скорость обучения
  - `max_depth`: [3, 5] — глубина деревьев
  - `subsample`: [0.8] — доля выборки для обучения каждого дерева
  - `min_samples_split`: [2, 5] — минимальное количество для разделения
  - `min_samples_leaf`: [1] — минимальное количество в листе
- Всего комбинаций: 1 × 2 × 2 × 1 × 2 × 1 = 8 вариантов
**GradientBoosting**:
- `n_estimators`: 100
- `learning_rate`: 0.1
- `max_depth`: 5
- `subsample`: 0.8
- `min_samples_split`: 5
- `min_samples_leaf`: 1
Лучший ROC-AUC на CV: 0.9222
Опционально:

- StackingClassifier (с CV-логикой)
Назначение: Мета-ансамбль, комбинирующий предсказания базовых моделей
Базовая архитектура:
  - Базовые модели (Level-0):
    1. `DecisionTreeClassifier` (best_dt)
    2. `RandomForestClassifier` (best_rf)
    3. `GradientBoostingClassifier` (best_gb)
  - Мета-модель (Level-1): `LogisticRegression`
- Конфигурация:
  - `cv`: 5 — стратифицированная 5-фолдовая кросс-валидация
  - `passthrough`: False — использование только мета-признаков
  - `stack_method`: 'auto' — автоматический выбор метода стекинга
- Параметры мета-модели:
  - `C`: 1.0
  - `max_iter`: 1000
  - `random_state`: 42

## 4. Results

- Таблица/список финальных метрик на test по всем моделям

| Модель | Accuracy | Precision | Recall | F1-score | ROC-AUC |
|--------|----------|-----------|--------|----------|---------|
| Stacking | 0.9044 | 0.8716 | 0.7463 | 0.8041 | 0.9253 |
| GradientBoosting | 0.8928 | 0.8704 | 0.6956 | 0.7732 | 0.9237 |
| RandomForest | 0.8839 | 0.9125 | 0.6173 | 0.7364 | 0.9207 |
| DecisionTree | 0.8311 | 0.7134 | 0.5973 | 0.6502 | 0.8281 |
| LogisticRegression | 0.8211 | 0.7500 | 0.4789 | 0.5845 | 0.8163 |
| Dummy Baseline | 0.7372 | 0.0000 | 0.0000 | 0.0000 | 0.5000 |

- Победитель (по ROC-AUC или по согласованному критерию) и краткое объяснением
 **Stacking Classifier**
Краткое объяснение:
  Stacking Classifier показал наивысший **ROC-AUC = 0.9253**, превзойдя все отдельные модели. Это объясняется способностью мета-ансамбля: Комбинирование сильных сторон: Stacking объединил предсказания трех лучших базовых моделей (DecisionTree, RandomForest, GradientBoosting), используя LogisticRegression как мета-модель для "обучения" оптимального взвешивания их предсказаний

## 5. Analysis

- Устойчивость: что будет, если поменять `random_state` (хотя бы 5 прогонов для 1-2 моделей) – кратко

Для проверки устойчивости проведено 5 прогонов с разными значениями `random_state` для двух моделей: **RandomForest** и **GradientBoosting**. Цель — оценить, насколько результаты зависят от случайного разбиения данных.

**Результаты экспериментов**:

| random_state | RandomForest (AUC) | GradientBoosting (AUC) |
|------|--------------------|------------------------|
| 42 | 0.9262 | 0.8962 |
| 123 | 0.9285 | 0.8967 |
| 777 | 0.9347 | 0.9085 |
| 999 | 0.9338 | 0.9066 |
| 2024 | 0.9262 | 0.9013 |

Статистический анализ:

- **RandomForest**: Средний AUC = 0.9299 ± 0.0037 (диапазон: 0.9262-0.9347)
- **GradientBoosting**: Средний AUC = 0.9019 ± 0.0050 (диапазон: 0.8962-0.9085)

**Ключевые наблюдения**:

1. RandomForest более устойчив
2. GradientBoosting показывает большую вариативность

В основном эксперименте GradientBoosting показал лучший результат (0.9237 vs 0.9207), однако при проверке устойчивости RandomForest демонстрирует:

- Более высокое среднее значение (0.9299 vs 0.9019)
- Лучшую устойчивость (меньший разброс)

Заключение: Хотя GradientBoosting показал лучший результат в основном эксперименте, проверка устойчивости выявила преимущество RandomForest по стабильности. Это подчеркивает важность многократных прогонов при оценке моделей и необходимость учитывать не только пиковую производительность, но и воспроизводимость результатов.

- Ошибки: confusion matrix для лучшей модели + комментарий

|  -|0|1|
|---|---|---|
|0|2550|104|
|1|240|706|

| Показатель | Значение |
|------------|----------|
| True Negative (TN) | 2550 |
| False Positive (FP) | 104 |
| False Negative (FN) | 240 |
| True Positive (TP) | 706 |

| **Всего** | **3600** | 2550 + 104 + 240 + 706 |

Процентный анализ (от общего количества 3600 образцов):

- Правильные предсказания: 90.44% (2550 + 706) / 3600
- Ошибочные предсказания: 9.56% (104 + 240) / 3600
- Дисбаланс классов в данных:
  - Класс 0 ("хорошие"): 73.72% (2654/3600)
  - Класс 1 ("плохие"): 26.28% (946/3600)

Матрица показывает, что модель достигает высокой общей точности (90.4%) при прогнозировании бинарной классификации.
Основная характеристика работы модели — выраженный дисбаланс между типами ошибок. Модель пропускает значительное количество положительных случаев (240, или 25% от общего числа), что указывает на умеренную чувствительность. В то же время она демонстрирует высокую специфичность, ошибаясь лишь в 104 случаях (4%) при идентификации отрицательного класса.
Такой паттерн ошибок свидетельствует о консервативной стратегии классификации: модель склонна минимизировать ложные срабатывания, предпочитая пропустить часть положительных случаев, но не ошибиться в отрицательных. Это подтверждается метриками Precision (87%) и Recall (75%) — модель надежна в положительных предсказаниях, но обнаруживает не все положительные случаи в данных.

- Интерпретация: permutation importance (top-10/15) + выводы

**Топ-15 самых важных признаков**:

| Ранг | Признак | Важность (ΔROC-AUC) | Относительная важность |
|------|---------|-------------------|------------------------|
| 1 | `f16` | 0.0650 ± 0.0018 | 100% |
| 2 | `f01` | 0.0251 ± 0.0017 | 38.7% |
| 3 | `f08` | 0.0157 ± 0.0011 | 24.1% |
| 4 | `f07` | 0.0133 ± 0.0015 | 20.5% |
| 5 | `f18` | 0.0129 ± 0.0009 | 19.9% |
| 6 | `f23` | 0.0117 ± 0.0018 | 18.0% |
| 7 | `f30` | 0.0110 ± 0.0016 | 16.9% |
| 8 | `f12` | 0.0103 ± 0.0012 | 15.8% |
| 9 | `f19` | 0.0100 ± 0.0016 | 15.4% |
| 10 | `f15` | 0.0088 ± 0.0013 | 13.5% |
| 11 | `f05` | 0.0076 ± 0.0008 | 11.6% |
| 12 | `f29` | 0.0074 ± 0.0011 | 11.4% |
| 13 | `f04` | 0.0060 ± 0.0013 | 9.2% |
| 14 | `f13` | 0.0059 ± 0.0011 | 9.1% |
| 15 | `f34` | 0.0054 ± 0.0008 | 8.4% |

1. Признак `f16` доминирует с важностью 0.0650, что в **2.6 раза** больше, чем у второго по важности признака `f01`. Перестановка `f16` снижает ROC-AUC на 6.5% — это критически важный признак для модели.

2. Топ-5 признаков (`f16`, `f01`, `f08`, `f07`, `f18`) обеспечивают **~60%** общей объяснительной силы, Топ-10 признаков покрывают **~85%** важности

3. Четкие кластеры важности:
   - Критически важные (0.01+): 9 признаков
   - Средней важности (0.005-0.01): 6 признаков  

## 6. Conclusion

3-6 коротких тезисов: что вы поняли про деревья/ансамбли и про честный ML-протокол.

О деревья/ансамблях:
Важно правильно регулировать деревья, чтобы они не переобучались, тогда они становятся устойчивой моделью.
Ансамбли значительно превосходят одиночные модели, но нужно правильно выбирать бэггинг или бустинг в зависимости от того, что требуется (интерпретируемость, устоичивость).
Объединение моделей через Stacking дает наилучший результат, что подверждает, что несколько объединеных моделей умнее одной.
О честном ML-протоколе:
DummyClassifier (ROC-AUC: 0.5) установил минимальный порог — любая осмысленная модель должна его преодолеть. Без baseline невозможно оценить реальный прогресс.
Жесткое разделение на train/validation/test (80/20/20) и использование кросс-валидации при подборе гиперпараметров предотвратили оптимистичные оценки на тренировочных данных.
Использование 5 метрик (Accuracy, Precision, Recall, F1, ROC-AUC) показало, что модели могут "выигрывать" по одним метрикам и "проигрывать" по другим. 