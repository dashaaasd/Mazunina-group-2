# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

Вы выбрали 3 датасета из 4 (перечислите):

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: (строк, столбцов) 12000 строк, 9 столбцов
- Признаки: какие типы (числовые / категориальные) 8 числовых признаков
- Пропуски: есть/нет (где, сколько примерно) пропусков нет
- "Подлости" датасета: (разные шкалы / выбросы / разная плотность / высокая размерность / категориальные и т.д.) Числовые признаки в разных шкалах + шумовые признаки. Без масштабирования результаты обычно "едут".

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: (строк, столбцов) 8000 строк, 4 столбца
- Признаки: какие типы (числовые / категориальные) 3 числовых признака
- Пропуски: есть/нет (где, сколько примерно) пропусков нет
- "Подлости" датасета: (разные шкалы / выбросы / разная плотность / высокая размерность / категориальные и т.д.) Нелинейная структура + выбросы + лишний шумовой признак. Хорошо демонстрирует, где KMeans проигрывает.

### 1.3 Dataset C

- Файл: `S07-hw-dataset-03.csv`
- Размер: (строк, столбцов) 15000 строк, 5 столбцов
- Признаки: какие типы (числовые / категориальные) 4 числовых признака
- Пропуски: есть/нет (где, сколько примерно) пропусков нет
- "Подлости" датасета: (разные шкалы / выбросы / разная плотность / высокая размерность / категориальные и т.д.) Кластеры разной плотности + фоновый шум. Часто провоцирует ошибки выбора eps для DBSCAN.


## 2. Protocol

Опишите ваш "честный" unsupervised-протокол.

- Препроцессинг: что именно делали (scaling, imputation, encoding, PCA – если делали)
  - Стандартное масштабирование всех числовых признаков (StandardScaler)
  - Обработка пропусков: SimpleImputer со стратегией median (хотя пропусков не было)
  - Категориальных признаков не было, кодирование не требовалось
  - Использование Pipeline для последовательной обработки
- Поиск гиперпараметров:
  - какой диапазон/сетка параметров для KMeans (k) и второго метода (eps/min_samples или linkage/k)
    - KMeans: перебирали k от 2 до 20
    - DBSCAN: сетка eps = [0.3, 0.4, 0.5, 0.7, 1.0, 1.5, 2.0] и min_samples = [3, 5, 10, 15]
  - чем руководствовались при выборе "лучшего"
    - При выборе "лучшего" руководствовались максимизацией silhouette score
- Метрики: silhouette / Davies-Bouldin / Calinski-Harabasz (и как считали для DBSCAN при наличии шума)
  - silhouette_score, davies_bouldin_score, calinski_harabasz_score
  - Для DBSCAN: метрики считались только на non-noise точках (labels != -1), явно выводилась доля шума
- Визуализация: PCA(2D) (и t-SNE, если делали – с какими параметрами)
  - PCA(2D) с фиксированным random_state=42 для всех датасетов
  - Дополнительные графики: silhouette vs k для KMeans, сравнение результатов DBSCAN

## 3. Models

Перечислите, какие модели сравнивали **на каждом датасете**, и какие параметры подбирали.

Минимум (для каждого датасета):

- KMeans (поиск `k`, фиксировали `random_state`, `n_init`)
  - Диапазон k: от 2 до 20
  - random_state = 42
  - n_init = "auto" (или 10 для совместимости)
  - Метрика выбора: максимизация silhouette score
- Один из:
  - DBSCAN (`eps`, `min_samples`, доля шума)
    - eps: [0.3, 0.4, 0.5, 0.7, 1.0, 1.5, 2.0]
    - min_samples: [3, 5, 10, 15]
    - Учет шума (label = -1): вычислялась доля шума, метрики считались на non-noise точках, 
    или
  - AgglomerativeClustering (`k`, `linkage`) не использовался

Опционально: третий метод / дополнительные варианты параметров.

## 4. Results

Для каждого датасета – краткая сводка результатов.

### 4.1 Dataset A

- Лучший метод и параметры: KMeans с k=2
- Метрики: silhouette = 0.522, DB = 0.685, CH = 11787.0
- DBSCAN показал идентичный результат при eps=2.0, min_samples=3 (silhouette = 0.522, без шума)
- Коротко: датасет содержит два четко разделенных кластера, что подтверждается высоким значением silhouette. Оба алгоритма показывают одинаково хорошие результаты.

### 4.2 Dataset B

- Лучший метод и параметры: DBSCAN с eps=0.7, min_samples=15
- Метрики: silhouette = 0.349, DB = 0.820, CH = 133.2
- Доля шума: 5.1%
- Коротко: DBSCAN лучше справился с нелинейной структурой данных и выбросами, выделив 2 основных кластера с разумной долей шума. KMeans (silhouette=0.307) показал худший результат из-за неспособности обрабатывать сложную форму кластеров.

### 4.3 Dataset C

- Лучший метод и параметры: KMeans с k=3
- Метрики: silhouette = 0.316, DB = 1.158, CH = 6957.2
- DBSCAN: лучший результат при eps=0.3, min_samples=15 (silhouette=0.269, доля шума 29.9%)
- Коротко: KMeans показал лучший результат, что говорит о более компактной и сферической структуре кластеров. DBSCAN выделил много шума (почти 30%), что неоптимально для этого датасета.

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- Где KMeans "ломается" и почему?
  - KMeans "ломается" на датасете B из-за нелинейной структуры данных и наличия выбросов. Алгоритм предполагает сферические кластеры одинакового размера, что не соответствует реальной структуре данных.
- Где DBSCAN/иерархическая кластеризация выигрывают и почему?
  - DBSCAN выигрывает на датасете B благодаря способности:
    - Обнаруживать кластеры произвольной формы
    - Выделять выбросы как шум
    - Автоматически определять количество кластеров
- Что сильнее всего влияло на результат (масштабирование, выбросы, плотность, пропуски, категориальные признаки)?
  - Наибольшее влияние на результаты оказали:
  1. Масштабирование - критически важно для Dataset A, где признаки в разных шкалах
  2. Выбросы - Dataset B требовал алгоритма, устойчивого к выбросам
  3. Плотность кластеров - Dataset C с разной плотностью создавал проблемы для DBSCAN

### 5.2 Устойчивость (обязательно для одного датасета)

- Какую проверку устойчивости делали (5 запусков KMeans по разным seed или иной подход)
  - Проверка устойчивости проведена для Dataset A с KMeans (k=2)
  - Метод: 5 запусков с разными random_state (42, 123, 456, 789, 999)
- Что получилось (в 3-6 строк)
  - Полное совпадение разбиений: Все 5 запусков KMeans с разными random_state дали идентичные группировки точек. Adjusted Rand Index (ARI) между всеми парами запусков равен 1.0.
  - Перестановка меток: В некоторых запусках метки кластеров поменялись местами (например, кластер "0" стал "1" и наоборот), но состав точек в кластерах остался неизменным.
  - Абсолютная согласованность: Несмотря на случайную инициализацию центроидов, алгоритм всегда сходится к одному и тому же решению. Инерция (48425.91) идентична во всех запусках.
- Вывод: устойчиво/неустойчиво и почему вы так считаете
  - KMeans на этом датасете показывает абсолютную устойчивость благодаря четкому разделению кластеров. Все запуски дали идентичные разбиения.

### 5.3 Интерпретация кластеров

- Как вы интерпретировали кластеры:
  - профили признаков (средние/медианы) **или**
  - любая другая логичная интерпретация
  Для интерпретации использовался анализ средних значений признаков после масштабирования:
  - Dataset A
    - Кластер 0 (20%): характеризуется высокими значениями f01 (+1.813), f05 (+1.461) и низкими f03 (-1.946), f04 (-1.593)
    - Кластер 1 (80%): имеет умеренные значения всех признаков, близкие к нулю
    - Ключевые разделяющие признаки: f02 (0.674 vs -0.169, Δ=0.843) и f04 (-1.593 vs 0.398, Δ=1.991)
  - Dataset B: кластеры соответствуют разным областям пространства (x1, x2)
    - Кластер 0 (50.2%): положительный x1 (+0.684), отрицательный x2 (-0.671)
    - Кластер 1 (49.8%): отрицательный x1 (-0.690), положительный x2 (+0.677)
    - Шумовой признак z_noise не информативен (средние ≈0 в обоих кластерах)
  - Dataset C: три кластера различаются по значениям x1 и x2
    - Кластер 0 (24.5%): "высокий" кластер с положительными x1, x2, f_corr
    - Кластер 1 (32.7%): "средний" кластер с умеренным x1, отрицательным x2
    - Кластер 2 (42.8%): "низкий" кластер с отрицательными x1, f_corr
- 3-6 строк выводов
  - В каждом датасете есть 1-2 ключевых признака, наиболее различающиеся между кластерами
  - Большие различия в средних значениях,, подтверждают хорошее разделение кластера
  - Так же как и было в описание датасетов, есть шумовые признаки, которые не учавствуют в разделении датасетов
  - Первый датасет имеет сильно ассиметричные кластеры, что указывает на особую структуру, как и было в описание датасета

## 6. Conclusion

4-8 коротких тезисов: чему научились про кластеризацию, метрики и корректный протокол unsupervised-эксперимента.

- Предпроцессинг важная часть работы, без него результаты были бы некоректные
- Выбор алгоритма зависит от структуры данных, KMeans хорош для сферических кластеров, DBSCAN -  для произвольных форм и наличия шума.
- Silhouette score хорошо коррелирует с визуальной оценкой качества кластеризации, что говорит нам о том, что это надежная метрика
- Визуализация PCA(2D)  помогает понять структуру данных и оценить качество класстеризации, даже при высокой размерности
- Не существует универсального лучшего алгоритма, Выбор зависит от специфики данных (шкалы, выбросы, плотность, форма кластеров).
